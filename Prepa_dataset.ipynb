{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ace7a661-83f7-4e24-9529-6110f492fab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1ba17d6-bbf6-459d-be10-8cda143a0137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = 1177989684\n",
    "import tensorflow as tf\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d60f626-98dd-493b-a5f9-bfb5eb4c45c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsm = np.array(Image.open('Urbis/UrbDSMY21_RBC_50cm/UrbDSMY21_RBC_50cm.tif'))\n",
    "dtm = np.array(Image.open('Urbis/UrbDTMY21_RBC_50cm/UrbDTMY21_RBC_50cm.tif'))\n",
    "rgb = np.array(Image.open('Urbis/50cm_NS_RGB/50cm_NS_RGB.tif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3590de4d-03e2-4fa1-bc7d-2b8c036e265d",
   "metadata": {},
   "source": [
    "## Preparation of 512x512 and 256x256 patches from the full map\n",
    "The patches (in the form of np ndarrays) are randomly split into train, test and val datasets <br>\n",
    "For each patch, a version with and without the rgb channels is saved, as well as the dtm supervision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb12ada5-e596-488e-94a3-4f4f0e12e599",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "val = dsm[0][0]\n",
    "y = 0\n",
    "\n",
    "windows = []\n",
    "\n",
    "for i in range(0, dsm.shape[0]-512,512):\n",
    "    #print(i)\n",
    "    for j in range(dsm.shape[1]):\n",
    "        if y >= dsm.shape[1] - 512:\n",
    "            y = 0\n",
    "            break\n",
    "        if not val in dsm[i:i+512,y:y+512]:\n",
    "            windows.append((i,y))\n",
    "            y += 512\n",
    "            n+=1\n",
    "        else : \n",
    "            y += 1\n",
    "            \n",
    "print(n)                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44656d08-adb7-4aa3-8313-c47a8aa24443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_dif(list1, list2):\n",
    "    res = list1\n",
    "    for item in list2:\n",
    "        res.remove(item)\n",
    "    return res\n",
    "\n",
    "items = list(range(n))\n",
    "train = random.sample(items, int(0.85*n))\n",
    "items = list_dif(items, train)\n",
    "test = random.sample(items, int(0.1*n))\n",
    "val = list_dif(items, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d786b14-52ac-4181-bc61-e5d060159436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(images_list, sample, name):\n",
    "    id512 = 1\n",
    "    id256 = 1\n",
    "    for item in sample:\n",
    "        w = images_list[item]\n",
    "        arr = dsm[w[0]:w[0]+512,w[1]:w[1]+512]\n",
    "        arr_dtm = dtm[w[0]:w[0]+512,w[1]:w[1]+512]\n",
    "        arr_rgb = np.concatenate((arr.reshape(arr.shape[0], arr.shape[1],1), rgb[w[0]:w[0]+512,w[1]:w[1]+512]), axis=2)\n",
    "        np.save('np_dataset/512/' + name + '/' + str(id512), arr)\n",
    "        np.save('np_dataset/512/' + name + '/rgb_' + str(id512), arr_rgb)\n",
    "        np.save('np_dataset/512/' + name + '/dtm_' + str(id512), arr_dtm)\n",
    "        id512+=1\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                arr_256 = arr[i*256:(i+1)*256, j*256:(j+1)*256]\n",
    "                arr_256_rgb = arr_rgb[i*256:(i+1)*256, j*256:(j+1)*256, :]\n",
    "                arr_dtm_256 = arr_dtm[i*256:(i+1)*256, j*256:(j+1)*256]\n",
    "                np.save('np_dataset/256/' + name + '/' + str(id256), arr_256)\n",
    "                np.save('np_dataset/256/' + name + '/rgb_' + str(id256), arr_256_rgb)\n",
    "                np.save('np_dataset/256/' + name + '/dtm_' + str(id256), arr_dtm_256)\n",
    "                id256 += 1\n",
    "        print(str(id512), end=\"\\r\")\n",
    "        time.sleep(.05)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b4e570-250e-4f70-91f4-015e7beaf15b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_images(windows, train, 'train')\n",
    "print('done train')\n",
    "save_images(windows, test, 'test')\n",
    "print('done test')\n",
    "save_images(windows, val, 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0549ed58-f73c-4235-95db-8929e7ae7607",
   "metadata": {},
   "source": [
    "## Preparation of the tensorflow datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd45b3ea-eada-423e-b35e-75ae021b559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83a1bc08-080a-44a4-91aa-47a992abe50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(image_id, res, dataset='train', rgb = False):\n",
    "    if rgb:\n",
    "        input_image = np.load('np_dataset/' + res + '/'+ dataset + '/rgb_' + image_id + '.npy')\n",
    "    else:\n",
    "        input_image = np.load('np_dataset/' + res + '/'+ dataset + '/' + image_id + '.npy')\n",
    "    real_image = np.load('np_dataset/' + res + '/'+ dataset + '/dtm_' + image_id + '.npy')\n",
    "    return input_image, real_image\n",
    "\n",
    "def normalize(dsm):\n",
    "    dsm /= np.max(dsm)\n",
    "    return dsm\n",
    "\n",
    "def normalize_rgb(image):\n",
    "    image = (image / 127.5) - 1\n",
    "    return image   \n",
    "\n",
    "def make_dataset(res, dataset='train', rgb = False):\n",
    "    input_images = []\n",
    "    real_images = []\n",
    "    path = 'np_dataset/' + res + '/' + dataset\n",
    "    id_list = [name[4:-4] for name in os.listdir(path) if 'dtm' in name]\n",
    "    N = str(len(id_list))\n",
    "    i = 0\n",
    "    for num in id_list[:1200]:\n",
    "        input_image, real_image = load(num, res, dataset, rgb)\n",
    "        if rgb:\n",
    "            input_image[:,:,1:] = normalize_rgb(input_image[:,:,1:])\n",
    "            input_image[:,:,0] = normalize(input_image[:,:,0])\n",
    "            real_image /= np.max(input_image[:,:,0])\n",
    "        else:\n",
    "            input_image = normalize(input_image)\n",
    "            real_image /= np.max(input_image)\n",
    "        input_images.append(input_image)\n",
    "        real_images.append(real_image)\n",
    "        i += 1\n",
    "        print(str(i) + '/' + N, end='\\r')\n",
    "        time.sleep(.01)\n",
    "    return np.array(input_images), np.array(real_images)\n",
    "\n",
    "def reshape_tf(item, res, rgb):\n",
    "    dsm, dtm = item[0], item[1]\n",
    "    res = int(res)\n",
    "    if not rgb: \n",
    "        dsm = tf.reshape(dsm, (res,res,1))\n",
    "    return (dsm, tf.reshape(dtm, (res,res,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a22cf63-084a-4388-a2ff-f53f131887fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tf_dataset(res, dataset='train', rgb = False):\n",
    "    input_ds, real_ds = make_dataset(res, dataset=dataset, rgb=rgb)\n",
    "    tf_dataset = tf.data.Dataset.from_tensor_slices((input_ds, real_ds))\n",
    "    tf_dataset = tf_dataset.map(lambda x, y: reshape_tf((x,y), res,rgb))\n",
    "    tf_dataset = tf_dataset.batch(BATCH_SIZE)\n",
    "    print(str(res) + ' ' + str(dataset) + ' ' + str(rgb) + ' done')\n",
    "    return tf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e79bcdc3-fc5f-4548-ae60-b97584797e63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 test True done\n"
     ]
    }
   ],
   "source": [
    "#train_dataset_512 = make_tf_dataset('512')\n",
    "#train_dataset_512.save('tf_dataset/train_dataset_512')\n",
    "\n",
    "#test_dataset_512 = make_tf_dataset('512', dataset='test')\n",
    "#test_dataset_512.save('tf_dataset/test_dataset_512')\n",
    "\n",
    "#train_dataset_256 = make_tf_dataset('256')\n",
    "#train_dataset_256.save('tf_dataset/train_dataset_256')\n",
    "\n",
    "#test_dataset_256 = make_tf_dataset('256', dataset='test')\n",
    "#test_dataset_256.save('tf_dataset/test_dataset_256')\n",
    "\n",
    "#train_dataset_rgb_512 = make_tf_dataset('512', rgb = True)\n",
    "#train_dataset_rgb_512.save('tf_dataset/train_dataset_rgb_512')\n",
    "\n",
    "test_dataset_rgb_512 = make_tf_dataset('512', dataset='test', rgb = True)\n",
    "test_dataset_rgb_512.save('tf_dataset/test_dataset_rgb_512')\n",
    "\n",
    "#train_dataset_rgb_256 = make_tf_dataset('256', rgb = True)\n",
    "#train_dataset_rgb_256.save('tf_dataset/train_dataset_rgb_256')\n",
    "\n",
    "#test_dataset_rgb_256 = make_tf_dataset('256', dataset='test', rgb = True)\n",
    "#test_dataset_rgb_256 = test_dataset_rgb_256.save('tf_dataset/test_dataset_rgb_256')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75571ad2-6625-4319-82fb-3335c714ad0b",
   "metadata": {},
   "source": [
    "## Loading saved tf dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449be31e-1e5d-43fd-8ab3-18391aaa4f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_ds = tf.data.Dataset.load('tf_dataset/train_dataset_256_rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77619cbd-a1db-4118-a4ea-738dc60cc893",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example = [item for item in current_ds.take(1)]\n",
    "example[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff7f75d-69c4-402e-beab-6171672f1c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(reshape_tf(example[0], '256', False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1545de0b-3035-4f67-8135-d70740473537",
   "metadata": {},
   "source": [
    "Error in the shape of the images in the dataset --> instead of remaking the dataset they are loaded and reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201b9935-9314-4833-aed0-00d4a5658c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [item for item in current_ds.take(1)]\n",
    "inp, re = example[0][0], example[0][1]\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0bc15f-8970-44fb-9d81-78739d3a5634",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in current_ds.take(6):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(item[0][0])\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(item[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a607a030-d625-41e6-bdf4-609e5c5b68fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
